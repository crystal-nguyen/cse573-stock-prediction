{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0adcbc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whatsapp limits text forwards to five recipien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exclusive tesla holds battery supply talks wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple is holding a global iphone photography c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the pros and cons of buying apple stock ahead ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hoosier companies among most admired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  whatsapp limits text forwards to five recipien...      1\n",
       "1  exclusive tesla holds battery supply talks wit...      1\n",
       "2  apple is holding a global iphone photography c...      1\n",
       "3  the pros and cons of buying apple stock ahead ...      1\n",
       "4               hoosier companies among most admired      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "news = pd.read_csv('w2v_news.csv').drop(columns=['Unnamed: 0'])\n",
    "news = news.dropna()\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e41941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84554"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('w2v_tweets.csv').drop(columns=['Unnamed: 0'])\n",
    "tweets = tweets.dropna()\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe11357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOLLARSIGN they def set up the open to sell a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOLLARSIGN DOLLARSIGN DOLLARSIGN DOLLARSIGN go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latest apple pay deal offers DOLLARSIGN tacos ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOLLARSIGN DOLLARSIGN easymoneylucy DOLLARSIGN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HASHTAG airpods price durability affecting sal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  DOLLARSIGN they def set up the open to sell a ...      1\n",
       "1  DOLLARSIGN DOLLARSIGN DOLLARSIGN DOLLARSIGN go...      0\n",
       "2  latest apple pay deal offers DOLLARSIGN tacos ...      0\n",
       "3  DOLLARSIGN DOLLARSIGN easymoneylucy DOLLARSIGN...      1\n",
       "4  HASHTAG airpods price durability affecting sal...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927580f1",
   "metadata": {},
   "source": [
    "## Method 3: Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d79751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "flagged = news['text'].apply(lambda x: word_tokenize(str(x)))\n",
    "news['remove_stopwords'] = flagged.apply(lambda x: ' '.join([x for x in x if x not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f28e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>target, price, aapl, apple, DOLLARSIGN, 00, gi...</td>\n",
       "      <td>[whatsapp, limits, text, forwards, five, recip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>faang, netflix, nflx, stock, apple, hold, bull...</td>\n",
       "      <td>[exclusive, tesla, holds, battery, supply, tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>alphabet, apple, chief, google, aapl, finally,...</td>\n",
       "      <td>[apple, holding, global, iphone, photography, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>surges, apple, stock, market, decision, amazon...</td>\n",
       "      <td>[pros, cons, buying, apple, stock, ahead, earn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>2018, technology, sector, update, 12, stock, f...</td>\n",
       "      <td>[hoosier, companies, among, admired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>apple, faangs, na, rates, 29, impact, software...</td>\n",
       "      <td>[weekly, qualcomm, incorporated, nasdaq, qcom,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>tesla, apple, amazon, go, stock, alibaba, vs, ...</td>\n",
       "      <td>[tesla, talks, china, lishen, shanghai, batter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>target, price, aapl, apple, DOLLARSIGN, 00, gi...</td>\n",
       "      <td>[facebook, whatsapp, limits, users, five, text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>stocks, trade, us, january, wall, china, fears...</td>\n",
       "      <td>[stocks, sink, economic, concerns, hit, davos,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>faang, netflix, nflx, stock, apple, hold, bull...</td>\n",
       "      <td>[intel, intc, q4, earnings, preview, client, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0            28.0              0.3409   \n",
       "1            1            13.0              0.2282   \n",
       "2            2            43.0              0.7521   \n",
       "3            3            38.0              0.8768   \n",
       "4            4            44.0              0.4812   \n",
       "5            5             1.0              0.3024   \n",
       "6            6            24.0              0.4335   \n",
       "7            7            28.0              0.5656   \n",
       "8            8            36.0              0.2171   \n",
       "9            9            13.0              0.6267   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  target, price, aapl, apple, DOLLARSIGN, 00, gi...   \n",
       "1  faang, netflix, nflx, stock, apple, hold, bull...   \n",
       "2  alphabet, apple, chief, google, aapl, finally,...   \n",
       "3  surges, apple, stock, market, decision, amazon...   \n",
       "4  2018, technology, sector, update, 12, stock, f...   \n",
       "5  apple, faangs, na, rates, 29, impact, software...   \n",
       "6  tesla, apple, amazon, go, stock, alibaba, vs, ...   \n",
       "7  target, price, aapl, apple, DOLLARSIGN, 00, gi...   \n",
       "8  stocks, trade, us, january, wall, china, fears...   \n",
       "9  faang, netflix, nflx, stock, apple, hold, bull...   \n",
       "\n",
       "                                                Text  \n",
       "0  [whatsapp, limits, text, forwards, five, recip...  \n",
       "1  [exclusive, tesla, holds, battery, supply, tal...  \n",
       "2  [apple, holding, global, iphone, photography, ...  \n",
       "3  [pros, cons, buying, apple, stock, ahead, earn...  \n",
       "4               [hoosier, companies, among, admired]  \n",
       "5  [weekly, qualcomm, incorporated, nasdaq, qcom,...  \n",
       "6  [tesla, talks, china, lishen, shanghai, batter...  \n",
       "7  [facebook, whatsapp, limits, users, five, text...  \n",
       "8  [stocks, sink, economic, concerns, hit, davos,...  \n",
       "9  [intel, intc, q4, earnings, preview, client, c...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "words = news['remove_stopwords'].apply(lambda x: str(x).split(' ')).tolist()\n",
    "id2word = corpora.Dictionary(words)\n",
    "corpus = [id2word.doc2bow(text) for text in words]\n",
    "\n",
    "num_topics = 70\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word,num_topics=num_topics)\n",
    "\n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=words):\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=words)\n",
    "\n",
    "# Format\n",
    "lda_df = df_topic_sents_keywords.reset_index()\n",
    "lda_df.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "lda_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60b8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "    \n",
    "def get_corpus(x):\n",
    "    x = [i.strip() for i in x]\n",
    "    words = list(sent_to_words(x))\n",
    "    bigram_mod = bigrams(words)\n",
    "    bigram = [bigram_mod[review] for review in words]\n",
    "    id2word = gensim.corpora.Dictionary(bigram)\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.35)\n",
    "    id2word.compactify()\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram]\n",
    "    return corpus, id2word, bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7f9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(news['remove_stopwords'].tolist(), news['label'].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "train_corpus, train_id2word, bigram_train = get_corpus(X_train)\n",
    "\n",
    "test_corpus, test_id2word, bigram_test = get_corpus(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9749a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "X_train_sentiment = []\n",
    "for sample in X_train:\n",
    "    X_train_sentiment.append(sid.polarity_scores(sample)['compound'])\n",
    "    \n",
    "X_test_sentiment = []\n",
    "for sample in X_test:\n",
    "    X_test_sentiment.append(sid.polarity_scores(sample)['compound'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9facdf09",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "\n",
    "for i in range(len(train_corpus)):\n",
    "    top_topics = (\n",
    "        lda_model.get_document_topics(train_corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "    )\n",
    "    topic_vec = [top_topics[i][1] for i in range(70)]\n",
    "    topic_vec.append(X_train_sentiment[i])\n",
    "    train_vecs.append(topic_vec)\n",
    "\n",
    "X = np.array(train_vecs)\n",
    "y = np.array(y_train)\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "cv_lr_f1, cv_lr_accuracy  = [], []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train_kf, y_train_kf = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train_kf)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr_lda = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train_kf)\n",
    "\n",
    "    y_pred = lr_lda.predict(X_val_scale)\n",
    "    cv_lr_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    cv_lr_accuracy.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(f'Logistic Regression f1 score: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logistic Regression accuracy score: {np.mean(cv_lr_accuracy):.3f} +- {np.std(cv_lr_accuracy):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326a989",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609beeac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression f1 score:  0.5221354908552218\n",
      "Logistic Regression accuracy score:  0.5040506179409852\n"
     ]
    }
   ],
   "source": [
    "test_vecs = []\n",
    "for i in range(len(test_corpus)):\n",
    "    top_topics = (\n",
    "        lda_model.get_document_topics(test_corpus[i],\n",
    "                                      minimum_probability=0.0)\n",
    "    )\n",
    "    topic_vec = [top_topics[i][1] for i in range(70)]\n",
    "    topic_vec.append(X_test_sentiment[i])\n",
    "    test_vecs.append(topic_vec)\n",
    "\n",
    "X = np.array(test_vecs)\n",
    "y = np.array(y_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test_scale = scaler.fit_transform(X)\n",
    "\n",
    "y_pred = lr_lda.predict(X_test_scale)\n",
    "\n",
    "print('Logistic Regression f1 score: ', f1_score(y, y_pred, average='binary'))\n",
    "print(\"Logistic Regression accuracy score: \", accuracy_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ca335",
   "metadata": {},
   "source": [
    "### Method 1: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e715aa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whatsapp limits text forwards to five recipien...</td>\n",
       "      <td>1</td>\n",
       "      <td>whatsapp limits text forwards five recipients ...</td>\n",
       "      <td>[whatsapp, limits, text, forwards, to, five, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exclusive tesla holds battery supply talks wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>exclusive tesla holds battery supply talks chi...</td>\n",
       "      <td>[exclusive, tesla, holds, battery, supply, tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple is holding a global iphone photography c...</td>\n",
       "      <td>1</td>\n",
       "      <td>apple holding global iphone photography contes...</td>\n",
       "      <td>[apple, is, holding, a, global, iphone, photog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the pros and cons of buying apple stock ahead ...</td>\n",
       "      <td>1</td>\n",
       "      <td>pros cons buying apple stock ahead earnings</td>\n",
       "      <td>[the, pros, and, cons, of, buying, apple, stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hoosier companies among most admired</td>\n",
       "      <td>1</td>\n",
       "      <td>hoosier companies among admired</td>\n",
       "      <td>[hoosier, companies, among, most, admired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84549</th>\n",
       "      <td>during the last few days of 2016 the talk on w...</td>\n",
       "      <td>0</td>\n",
       "      <td>last days 2016 talk wall street ce</td>\n",
       "      <td>[during, the, last, few, days, of, 2016, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84550</th>\n",
       "      <td>copper rises bitcoin falls tim cook s pay soar...</td>\n",
       "      <td>0</td>\n",
       "      <td>copper rises bitcoin falls tim cook pay soars ...</td>\n",
       "      <td>[copper, rises, bitcoin, falls, tim, cook, s, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84551</th>\n",
       "      <td>stock market today stocks mixed as fangs advan...</td>\n",
       "      <td>0</td>\n",
       "      <td>stock market today stocks mixed fangs advance ...</td>\n",
       "      <td>[stock, market, today, stocks, mixed, as, fang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84552</th>\n",
       "      <td>during the last few days of 2016 the talk on w...</td>\n",
       "      <td>0</td>\n",
       "      <td>last days 2016 talk wall street ce</td>\n",
       "      <td>[during, the, last, few, days, of, 2016, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84553</th>\n",
       "      <td>you s stock index futures are set for a positi...</td>\n",
       "      <td>1</td>\n",
       "      <td>stock index futures set positive open inve</td>\n",
       "      <td>[you, s, stock, index, futures, are, set, for,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84552 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      whatsapp limits text forwards to five recipien...      1   \n",
       "1      exclusive tesla holds battery supply talks wit...      1   \n",
       "2      apple is holding a global iphone photography c...      1   \n",
       "3      the pros and cons of buying apple stock ahead ...      1   \n",
       "4                   hoosier companies among most admired      1   \n",
       "...                                                  ...    ...   \n",
       "84549  during the last few days of 2016 the talk on w...      0   \n",
       "84550  copper rises bitcoin falls tim cook s pay soar...      0   \n",
       "84551  stock market today stocks mixed as fangs advan...      0   \n",
       "84552  during the last few days of 2016 the talk on w...      0   \n",
       "84553  you s stock index futures are set for a positi...      1   \n",
       "\n",
       "                                        remove_stopwords  \\\n",
       "0      whatsapp limits text forwards five recipients ...   \n",
       "1      exclusive tesla holds battery supply talks chi...   \n",
       "2      apple holding global iphone photography contes...   \n",
       "3            pros cons buying apple stock ahead earnings   \n",
       "4                        hoosier companies among admired   \n",
       "...                                                  ...   \n",
       "84549                 last days 2016 talk wall street ce   \n",
       "84550  copper rises bitcoin falls tim cook pay soars ...   \n",
       "84551  stock market today stocks mixed fangs advance ...   \n",
       "84552                 last days 2016 talk wall street ce   \n",
       "84553         stock index futures set positive open inve   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [whatsapp, limits, text, forwards, to, five, r...  \n",
       "1      [exclusive, tesla, holds, battery, supply, tal...  \n",
       "2      [apple, is, holding, a, global, iphone, photog...  \n",
       "3      [the, pros, and, cons, of, buying, apple, stoc...  \n",
       "4             [hoosier, companies, among, most, admired]  \n",
       "...                                                  ...  \n",
       "84549  [during, the, last, few, days, of, 2016, the, ...  \n",
       "84550  [copper, rises, bitcoin, falls, tim, cook, s, ...  \n",
       "84551  [stock, market, today, stocks, mixed, as, fang...  \n",
       "84552  [during, the, last, few, days, of, 2016, the, ...  \n",
       "84553  [you, s, stock, index, futures, are, set, for,...  \n",
       "\n",
       "[84552 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['tokens'] = news['text'].apply(lambda x: x.split())\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683121e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 's',\n",
       " 'the',\n",
       " 'to',\n",
       " 'in',\n",
       " 'aapl',\n",
       " 'stock',\n",
       " 'market',\n",
       " 'as',\n",
       " 'DOLLARSIGN',\n",
       " 'by',\n",
       " 'for',\n",
       " 'stocks',\n",
       " 'is',\n",
       " 'a',\n",
       " 'of',\n",
       " 'on',\n",
       " 'and',\n",
       " 'inc',\n",
       " 'has',\n",
       " 'its',\n",
       " 'you',\n",
       " 'tech',\n",
       " 'dow',\n",
       " 'management',\n",
       " 'nasdaq',\n",
       " 'position',\n",
       " 'stake',\n",
       " 'earnings',\n",
       " 'amazon',\n",
       " 'million',\n",
       " 'new',\n",
       " '2018',\n",
       " 'holding',\n",
       " 'iphone',\n",
       " 'trade',\n",
       " 'shares',\n",
       " 'capital',\n",
       " 'update',\n",
       " 'declined',\n",
       " 'with',\n",
       " 'are',\n",
       " 'com',\n",
       " 'after',\n",
       " 'at',\n",
       " 'snapshot',\n",
       " 'buy',\n",
       " 'wall',\n",
       " 'marketwatch',\n",
       " 'street',\n",
       " 'china',\n",
       " 'it',\n",
       " 'value',\n",
       " 'this',\n",
       " 'not',\n",
       " 'price',\n",
       " 'from',\n",
       " 'why',\n",
       " 'rose',\n",
       " 'will',\n",
       " '3',\n",
       " 'facebook',\n",
       " 'news',\n",
       " 'what',\n",
       " 'investment',\n",
       " 'more',\n",
       " 'investors',\n",
       " 'p',\n",
       " 'be',\n",
       " 'here',\n",
       " 'report',\n",
       " 'but',\n",
       " 'up',\n",
       " 'cut',\n",
       " 'day',\n",
       " 'company',\n",
       " 'business',\n",
       " '5',\n",
       " 'how',\n",
       " '500',\n",
       " 'co',\n",
       " 'could',\n",
       " 'that',\n",
       " 'top',\n",
       " 'netflix',\n",
       " 'us',\n",
       " 'about',\n",
       " 'group',\n",
       " 'now',\n",
       " 'says',\n",
       " '1',\n",
       " 'microsoft',\n",
       " 'google',\n",
       " 'points',\n",
       " 'lowered',\n",
       " 'trump',\n",
       " 'big',\n",
       " 'share',\n",
       " 'markets',\n",
       " 'futures',\n",
       " '10',\n",
       " 'may',\n",
       " 'valuation',\n",
       " '2019',\n",
       " 'week',\n",
       " 'decreased',\n",
       " '2',\n",
       " 'first',\n",
       " 'trimmed',\n",
       " 'higher',\n",
       " 'growth',\n",
       " 'than',\n",
       " 'asset',\n",
       " 'data',\n",
       " 'advisors',\n",
       " 'technology',\n",
       " 'increased',\n",
       " 'should',\n",
       " 'rally',\n",
       " 'billion',\n",
       " 'over',\n",
       " 'sector',\n",
       " 'analysts',\n",
       " 'year',\n",
       " 'your',\n",
       " 'ahead',\n",
       " 'llc',\n",
       " 'investor',\n",
       " 'financial',\n",
       " 'time',\n",
       " 'global',\n",
       " 'shareholder',\n",
       " 'holder',\n",
       " 'best',\n",
       " 'raised',\n",
       " 'sales',\n",
       " 'watch',\n",
       " 'just',\n",
       " 'amzn',\n",
       " 'bank',\n",
       " 'most',\n",
       " 'while',\n",
       " 'have',\n",
       " 'boosted',\n",
       " 'ltd',\n",
       " 'an',\n",
       " 'lower',\n",
       " 'off',\n",
       " 'back',\n",
       " 'down',\n",
       " 'key',\n",
       " 'today',\n",
       " 'upped',\n",
       " 'target',\n",
       " 'gains',\n",
       " 'high',\n",
       " '4',\n",
       " 'these',\n",
       " 'lifted',\n",
       " 'buffett',\n",
       " 'trillion',\n",
       " 'companies',\n",
       " 'fed',\n",
       " 'set',\n",
       " 'faang',\n",
       " 'war',\n",
       " 'partners',\n",
       " 'qualcomm',\n",
       " 'can',\n",
       " 'daily',\n",
       " 'or',\n",
       " 'all',\n",
       " 'investing',\n",
       " 'fb',\n",
       " 'holdings',\n",
       " 'record',\n",
       " 'out',\n",
       " 'tesla',\n",
       " 'spotify',\n",
       " '6',\n",
       " 'into',\n",
       " 'jobs',\n",
       " 'know',\n",
       " '7',\n",
       " 'lp',\n",
       " 'next',\n",
       " 'still',\n",
       " 'intel',\n",
       " 'do',\n",
       " '000',\n",
       " 'trust',\n",
       " 'money',\n",
       " 'one',\n",
       " 'things',\n",
       " 'alphabet',\n",
       " 'right',\n",
       " 'end',\n",
       " 'iphones',\n",
       " 'msft',\n",
       " 'reuters',\n",
       " '00',\n",
       " 'services',\n",
       " 'get',\n",
       " 'strong',\n",
       " 'biggest',\n",
       " 'chip',\n",
       " 'jones',\n",
       " 'etfs',\n",
       " 'i',\n",
       " 'point',\n",
       " 'quarter',\n",
       " 'energy',\n",
       " 'fall',\n",
       " 'falls',\n",
       " 'hit',\n",
       " 'warren',\n",
       " 'nyse',\n",
       " 'dividend',\n",
       " 'de',\n",
       " 'etf',\n",
       " 'close',\n",
       " 'sell',\n",
       " 'rise',\n",
       " 'analyst',\n",
       " 'cap',\n",
       " 't',\n",
       " 'wealth',\n",
       " 'googl',\n",
       " 'buying',\n",
       " 'gazette',\n",
       " 'ceo',\n",
       " 'thestreet',\n",
       " 'their',\n",
       " 'last',\n",
       " 'cook',\n",
       " 'fund',\n",
       " 'portfolio',\n",
       " 'dollar',\n",
       " 'since',\n",
       " 'x',\n",
       " 'january',\n",
       " 'revenue',\n",
       " 'no',\n",
       " 'need',\n",
       " 'again',\n",
       " 'world',\n",
       " 'like',\n",
       " 'make',\n",
       " 'observer',\n",
       " 'amid',\n",
       " 'take',\n",
       " 'corp',\n",
       " 'samsung',\n",
       " '18',\n",
       " 'norman',\n",
       " 'trading',\n",
       " 'tim',\n",
       " 'years',\n",
       " 'smart',\n",
       " 'tariffs',\n",
       " 'oil',\n",
       " 'cramer',\n",
       " 'nflx',\n",
       " 'rebound',\n",
       " 'rating',\n",
       " 'drop',\n",
       " 'session',\n",
       " 'deal',\n",
       " 'some',\n",
       " 'fears',\n",
       " 'look',\n",
       " 'ge',\n",
       " 'before',\n",
       " 'music',\n",
       " 'gain',\n",
       " 'hits',\n",
       " 'worries',\n",
       " 'streak',\n",
       " '12',\n",
       " 'corporation',\n",
       " 'goog',\n",
       " 'berkshire',\n",
       " 'if',\n",
       " 'was',\n",
       " 'monday',\n",
       " 'hold',\n",
       " 'better',\n",
       " '30',\n",
       " 'index',\n",
       " 'research',\n",
       " 'chinese',\n",
       " 'fool',\n",
       " 'another',\n",
       " '11',\n",
       " 'worst',\n",
       " 'own',\n",
       " 'sentiment',\n",
       " 'open',\n",
       " 'motley',\n",
       " 'expected',\n",
       " 'we',\n",
       " 'results',\n",
       " 'friday',\n",
       " 'tax',\n",
       " 'video',\n",
       " '8',\n",
       " 'selloff',\n",
       " 'hot',\n",
       " 'boost',\n",
       " 'talks',\n",
       " 'streaming',\n",
       " 'focus',\n",
       " 'ipo',\n",
       " '0',\n",
       " 'outlook',\n",
       " 'move',\n",
       " 'sells',\n",
       " 'lead',\n",
       " 'america',\n",
       " 'major',\n",
       " 'morning',\n",
       " 'zacks',\n",
       " 'american',\n",
       " 'estimates',\n",
       " '100',\n",
       " 'chart',\n",
       " 'buys',\n",
       " '9',\n",
       " 'associates',\n",
       " '20',\n",
       " 'does',\n",
       " 'bullish',\n",
       " 'reports',\n",
       " 'other',\n",
       " 'rises',\n",
       " 'pay',\n",
       " 'cash',\n",
       " 'app',\n",
       " 'based',\n",
       " 'apos',\n",
       " 'amd',\n",
       " 'boeing',\n",
       " 'st',\n",
       " 'options',\n",
       " 'bitcoin',\n",
       " 'bear',\n",
       " 'roundup',\n",
       " 'win',\n",
       " 'expect',\n",
       " 'eps',\n",
       " 'goldman',\n",
       " 'nvidia',\n",
       " 'ibm',\n",
       " 'good',\n",
       " 'profit',\n",
       " 'snap',\n",
       " 'analysis',\n",
       " 'long',\n",
       " 'q4',\n",
       " 'q1',\n",
       " 'latest',\n",
       " 'drops',\n",
       " 'asian',\n",
       " 'cuts',\n",
       " 'there',\n",
       " 'mixed',\n",
       " 'tuesday',\n",
       " 'warning',\n",
       " 'q3',\n",
       " 'vs',\n",
       " 'micron',\n",
       " 'plans',\n",
       " 'beat',\n",
       " 'february',\n",
       " '200',\n",
       " 'rule',\n",
       " 'smartphone',\n",
       " 'continues',\n",
       " 'q2',\n",
       " 'track',\n",
       " 'thursday',\n",
       " 'sold',\n",
       " 'would',\n",
       " 'largest',\n",
       " 'reasons',\n",
       " 'kitco',\n",
       " 'so',\n",
       " 'decline',\n",
       " 'morgan',\n",
       " 'october',\n",
       " 'service',\n",
       " 'fitbit',\n",
       " 'wednesday',\n",
       " 'invest',\n",
       " 'health',\n",
       " 'highs',\n",
       " 'month',\n",
       " 'who',\n",
       " 'yields',\n",
       " 'disney',\n",
       " 'under',\n",
       " 'ipad',\n",
       " 'tensions',\n",
       " 'finance',\n",
       " 'making',\n",
       " 'home',\n",
       " 'march',\n",
       " 'alibaba',\n",
       " 'international',\n",
       " 'future',\n",
       " 'roku',\n",
       " 'poised',\n",
       " 'prices',\n",
       " 'even',\n",
       " 'weigh',\n",
       " 'two',\n",
       " 'show',\n",
       " 'devices',\n",
       " 'slide',\n",
       " '25',\n",
       " 'general',\n",
       " 'when',\n",
       " 'they',\n",
       " 'bull',\n",
       " 'weekly',\n",
       " 'way',\n",
       " 'keep',\n",
       " 'correction',\n",
       " 'looks',\n",
       " 'investments',\n",
       " 'call',\n",
       " 'see',\n",
       " 'much',\n",
       " 'bond',\n",
       " 'twitter',\n",
       " '15',\n",
       " '13',\n",
       " 'gets',\n",
       " 'demand',\n",
       " 'huawei',\n",
       " 'bac',\n",
       " 'launch',\n",
       " 'shorts',\n",
       " 'average',\n",
       " 'low',\n",
       " 'second',\n",
       " 'risk',\n",
       " 'fang',\n",
       " 'concerns',\n",
       " 'too',\n",
       " 'nearly',\n",
       " 'store',\n",
       " '26',\n",
       " 'plc',\n",
       " 'shows',\n",
       " 'privacy',\n",
       " 'en',\n",
       " 'start',\n",
       " 'asia',\n",
       " 'la',\n",
       " 'holiday',\n",
       " 'been',\n",
       " 'despite',\n",
       " 'ai',\n",
       " 'records',\n",
       " 'xs',\n",
       " 'chips',\n",
       " 'hathaway',\n",
       " 'adjustment',\n",
       " 'traders',\n",
       " 'parameter',\n",
       " 'leads',\n",
       " 'homepod',\n",
       " 'november',\n",
       " 'go',\n",
       " 'bloomberg',\n",
       " 'c',\n",
       " 'september',\n",
       " 'volatility',\n",
       " 'might',\n",
       " 'selling',\n",
       " 'campus',\n",
       " 'intc',\n",
       " 'reportedly',\n",
       " 'cnn',\n",
       " 'bulls',\n",
       " 'increases',\n",
       " 'weak',\n",
       " 'great',\n",
       " 'funds',\n",
       " 'losses',\n",
       " 'bought',\n",
       " 'going',\n",
       " 'say',\n",
       " 'alpha',\n",
       " '14',\n",
       " 'straight',\n",
       " 'qqq',\n",
       " 'sees',\n",
       " 'national',\n",
       " 'consumer',\n",
       " 'people',\n",
       " 'w',\n",
       " 'seeking',\n",
       " 'surge',\n",
       " 'tumble',\n",
       " 'huge',\n",
       " 'active',\n",
       " 'continue',\n",
       " 'help',\n",
       " 'given',\n",
       " 'rumors',\n",
       " 'europe',\n",
       " 'his',\n",
       " 'were',\n",
       " 'recap',\n",
       " 'july',\n",
       " 'economy',\n",
       " 'supplier',\n",
       " 'equity',\n",
       " 'eu',\n",
       " 'stanley',\n",
       " 'event',\n",
       " 'yahoo',\n",
       " 'season',\n",
       " 'cloud',\n",
       " 'august',\n",
       " 'post',\n",
       " 'barron',\n",
       " 'dip',\n",
       " 'getting',\n",
       " 'sinks',\n",
       " 'nike',\n",
       " 'mobile',\n",
       " 'which',\n",
       " 'commentary',\n",
       " 'broadcom',\n",
       " 'сша',\n",
       " 'picks',\n",
       " 'plunge',\n",
       " 'counsel',\n",
       " '_证券_腾讯网',\n",
       " 'retail',\n",
       " 'worth',\n",
       " 'against',\n",
       " 'spy',\n",
       " 'tsla',\n",
       " 'run',\n",
       " 'speaker',\n",
       " 'december',\n",
       " 'на',\n",
       " 'media',\n",
       " 'want',\n",
       " 'only',\n",
       " 'cheap',\n",
       " 'my',\n",
       " 'bad',\n",
       " 'computer',\n",
       " 'plan',\n",
       " 'positive',\n",
       " 'xr',\n",
       " 'electric',\n",
       " 'extend',\n",
       " 'mad',\n",
       " 'faangs',\n",
       " 'baba',\n",
       " 'following',\n",
       " 'guidance',\n",
       " 'united',\n",
       " 'bounce',\n",
       " 'european',\n",
       " 'suppliers',\n",
       " 'strategy',\n",
       " 'free',\n",
       " 'short',\n",
       " 'industry',\n",
       " 'pro',\n",
       " 'give',\n",
       " '2017',\n",
       " 'losing',\n",
       " 'soars',\n",
       " 'turn',\n",
       " 'aktie',\n",
       " 'tv',\n",
       " 'early',\n",
       " 'takes',\n",
       " 'mu',\n",
       " 'jump',\n",
       " 'd',\n",
       " 'really',\n",
       " 'jumps',\n",
       " 'na',\n",
       " 'micro',\n",
       " 'mark',\n",
       " 'sachs',\n",
       " 'silicon',\n",
       " 'makes',\n",
       " 'yet',\n",
       " 'rate',\n",
       " 'closes',\n",
       " 'did',\n",
       " 'giants',\n",
       " 'ever',\n",
       " 'he',\n",
       " 'put',\n",
       " '19',\n",
       " 'climb',\n",
       " '50',\n",
       " 'review',\n",
       " 'three',\n",
       " 'months',\n",
       " 'had',\n",
       " 'blue',\n",
       " 'surges',\n",
       " 'play',\n",
       " 'made',\n",
       " 'because',\n",
       " 'valley',\n",
       " 'changes',\n",
       " 'tariff',\n",
       " 'semiconductor',\n",
       " 'bet',\n",
       " '24',\n",
       " 'territory',\n",
       " 'gold',\n",
       " '16',\n",
       " 'production',\n",
       " 'technologies',\n",
       " 'l',\n",
       " 'coming',\n",
       " 'csco',\n",
       " 'strength',\n",
       " 'm',\n",
       " 'v',\n",
       " 'hedge',\n",
       " 'weakness',\n",
       " 'third',\n",
       " 'security',\n",
       " 'private',\n",
       " 'signs',\n",
       " 'term',\n",
       " 'rout',\n",
       " 'moves',\n",
       " 'red',\n",
       " 'tumbles',\n",
       " 'j',\n",
       " 'face',\n",
       " 'alexa',\n",
       " 'must',\n",
       " 'likely',\n",
       " 'securities',\n",
       " 'software',\n",
       " 'state',\n",
       " 'ch',\n",
       " 'slowdown',\n",
       " 'premarket',\n",
       " 'near',\n",
       " 'qcom',\n",
       " 'spending',\n",
       " '01',\n",
       " 'digital',\n",
       " 'edge',\n",
       " 'nightly',\n",
       " 'ios',\n",
       " 'thinking',\n",
       " 'story',\n",
       " 'cannot',\n",
       " 'crash',\n",
       " 'y',\n",
       " 'broader',\n",
       " 'launches',\n",
       " 'preview',\n",
       " 'got',\n",
       " 'internet',\n",
       " '17',\n",
       " 'plunges',\n",
       " 'push',\n",
       " 'driving',\n",
       " 'phone',\n",
       " 'taking',\n",
       " 'midday',\n",
       " 'raises',\n",
       " 'reaches',\n",
       " 'kpax',\n",
       " 'usa',\n",
       " 'bell',\n",
       " 'change',\n",
       " 'yield',\n",
       " 'love',\n",
       " 'industrial',\n",
       " 'away',\n",
       " 'april',\n",
       " 'meeting',\n",
       " 'finally',\n",
       " 'flat',\n",
       " 'forecast',\n",
       " 'ends',\n",
       " 'walmart',\n",
       " 'small',\n",
       " 'june',\n",
       " 'announces',\n",
       " 'jim',\n",
       " 'valuable',\n",
       " 'products',\n",
       " '27',\n",
       " 'economic',\n",
       " 'в',\n",
       " 'ktvq',\n",
       " 'systems',\n",
       " 'remain',\n",
       " 'corporate',\n",
       " 'real',\n",
       " 'wants',\n",
       " 'mac',\n",
       " 'rates',\n",
       " 'b',\n",
       " 'n',\n",
       " 'insider',\n",
       " 'ways',\n",
       " 'del',\n",
       " 'below',\n",
       " 'five',\n",
       " '29',\n",
       " 'threat',\n",
       " 'jpmorgan',\n",
       " 'retirement',\n",
       " 'part',\n",
       " 'posts',\n",
       " 'sink',\n",
       " 'td',\n",
       " 'display',\n",
       " 'musk',\n",
       " 'movement',\n",
       " 'credit',\n",
       " 'come',\n",
       " '3rd',\n",
       " 'never',\n",
       " 'them',\n",
       " 'caterpillar',\n",
       " 'macbook',\n",
       " 'powell',\n",
       " 'reversal',\n",
       " 'giant',\n",
       " '300',\n",
       " 'buybacks',\n",
       " 'tops',\n",
       " 'important',\n",
       " 'winners',\n",
       " 'led',\n",
       " 'game',\n",
       " 'loses',\n",
       " 'charts',\n",
       " 'public',\n",
       " 'recent',\n",
       " 'johnson',\n",
       " 'spot',\n",
       " 'ameritrade',\n",
       " 'popular',\n",
       " 'volatile',\n",
       " 'paypal',\n",
       " 'rising',\n",
       " 'weeks',\n",
       " '21',\n",
       " '600',\n",
       " 'advisory',\n",
       " 'decision',\n",
       " 'care',\n",
       " 'brief',\n",
       " 'boosts',\n",
       " 'per',\n",
       " 'use',\n",
       " 'case',\n",
       " 'court',\n",
       " 'holds',\n",
       " '5g',\n",
       " 'e',\n",
       " 'ロイター',\n",
       " 'advanced',\n",
       " 'where',\n",
       " 'HASHTAG',\n",
       " 'llp',\n",
       " 'optimism',\n",
       " 'pre',\n",
       " 'prime',\n",
       " 'growing',\n",
       " 'numbers',\n",
       " 'expectations',\n",
       " 'opening',\n",
       " 'advisers',\n",
       " 'healthcare',\n",
       " 'content',\n",
       " '800',\n",
       " '28',\n",
       " 'bill',\n",
       " '4th',\n",
       " 'opportunity',\n",
       " 'rallies',\n",
       " 'indexes',\n",
       " 'employees',\n",
       " 'massive',\n",
       " 'f',\n",
       " '08',\n",
       " 'ubs',\n",
       " 'apps',\n",
       " 'mid',\n",
       " 'behind',\n",
       " 'house',\n",
       " 'el',\n",
       " 'fortune',\n",
       " 'quarterly',\n",
       " 'opens',\n",
       " 'live',\n",
       " 'late',\n",
       " 'canada',\n",
       " 'needs',\n",
       " 'slump',\n",
       " 'hours',\n",
       " 'steve',\n",
       " 'managers',\n",
       " 'mostly',\n",
       " '23',\n",
       " 'lift',\n",
       " 'kbzk',\n",
       " 'woes',\n",
       " 'feature',\n",
       " 'am',\n",
       " 'breaks',\n",
       " 'york',\n",
       " 'warns',\n",
       " '07',\n",
       " 'past',\n",
       " '香港新浪',\n",
       " 'twtr',\n",
       " 'chief',\n",
       " 'brands',\n",
       " 'build',\n",
       " 'movers',\n",
       " 'limited',\n",
       " 'pressure',\n",
       " 'hopes',\n",
       " 'option',\n",
       " '400',\n",
       " 'sonos',\n",
       " 'break',\n",
       " 'among',\n",
       " 'upcoming',\n",
       " 'head',\n",
       " 'cost',\n",
       " 'list',\n",
       " 'salesforce',\n",
       " '31',\n",
       " 'winning',\n",
       " 'ibd',\n",
       " 'chase',\n",
       " 'slides',\n",
       " 'miss',\n",
       " 'above',\n",
       " 'texas',\n",
       " 'faces',\n",
       " 'cisco',\n",
       " 'bid',\n",
       " 'highlights',\n",
       " 'less',\n",
       " '06',\n",
       " 'retreat',\n",
       " 'die',\n",
       " 'imx',\n",
       " 'shutdown',\n",
       " 'users',\n",
       " 'support',\n",
       " 'during',\n",
       " 'foxconn',\n",
       " 'stop',\n",
       " 'days',\n",
       " 'pandora',\n",
       " 'beats',\n",
       " '05',\n",
       " 'fear',\n",
       " 'profits',\n",
       " 'zuckerberg',\n",
       " 'taiwan',\n",
       " 'called',\n",
       " 'problem',\n",
       " 'ups',\n",
       " 'action',\n",
       " 'talk',\n",
       " '22',\n",
       " 'climbs',\n",
       " 'trend',\n",
       " 'many',\n",
       " 'o',\n",
       " 'intl',\n",
       " 'means',\n",
       " 'starbucks',\n",
       " 'quotes',\n",
       " 'power',\n",
       " 'history',\n",
       " 'soon',\n",
       " 'keeps',\n",
       " 'large',\n",
       " 'impact',\n",
       " 'law',\n",
       " 'momentum',\n",
       " 'und',\n",
       " 'hurt',\n",
       " 'offer',\n",
       " 'become',\n",
       " 'upgrades',\n",
       " 'seen',\n",
       " 'ebay',\n",
       " 'elon',\n",
       " 'square',\n",
       " 'access',\n",
       " 'upbeat',\n",
       " 'lows',\n",
       " 'slumps',\n",
       " 'breaking',\n",
       " 'happenings',\n",
       " 'cl',\n",
       " 'solid',\n",
       " 'through',\n",
       " 'consider',\n",
       " 'midterm',\n",
       " 'reality',\n",
       " 'unveils',\n",
       " 'struggle',\n",
       " 'oracle',\n",
       " 'percent',\n",
       " 'falling',\n",
       " 'adobe',\n",
       " 'meltdown',\n",
       " 'interest',\n",
       " 'banks',\n",
       " 'our',\n",
       " 'potential',\n",
       " 'think',\n",
       " 'firm',\n",
       " 'around',\n",
       " 'super',\n",
       " 'deals',\n",
       " 'r',\n",
       " 'inflation',\n",
       " 'direction',\n",
       " 'weighs',\n",
       " 'inch',\n",
       " 'income',\n",
       " 'brexit',\n",
       " 'lose',\n",
       " 'negative',\n",
       " 'survey',\n",
       " 'government',\n",
       " 'strikes',\n",
       " 'ready',\n",
       " 'every',\n",
       " 'dis',\n",
       " 'fell',\n",
       " 'dropbox',\n",
       " 'nikkei',\n",
       " 'air',\n",
       " 'downgrades',\n",
       " 'smartphones',\n",
       " 'hardware',\n",
       " 'india',\n",
       " 'bonds',\n",
       " 'verizon',\n",
       " 'remains',\n",
       " 'self',\n",
       " 'plus',\n",
       " 'max',\n",
       " 'jitters',\n",
       " 'comments',\n",
       " 'race',\n",
       " 'old',\n",
       " 'siri',\n",
       " 'equities',\n",
       " 'attempt',\n",
       " 'performance',\n",
       " 'drive',\n",
       " 'der',\n",
       " 'trades',\n",
       " 'beyond',\n",
       " 'leading',\n",
       " 'lost',\n",
       " '2nd',\n",
       " '09',\n",
       " 'reported',\n",
       " 'sharply',\n",
       " 'life',\n",
       " 'cirrus',\n",
       " 'fight',\n",
       " 'revenues',\n",
       " 'usd',\n",
       " 'transcript',\n",
       " 'losers',\n",
       " 'citigroup',\n",
       " 'bears',\n",
       " 'industrials',\n",
       " 'line',\n",
       " 'slowing',\n",
       " 'half',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, word2vec\n",
    "X_train, X_test, y_train, y_test = train_test_split(news['tokens'], news['label'],test_size=0.2)\n",
    "w2v_model = gensim.models.Word2Vec(X_train,vector_size=100,window=5,min_count=2)\n",
    "w2v_model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9897a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_834/254471284.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words_set])\n",
      "/tmp/ipykernel_834/254471284.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words_set])\n"
     ]
    }
   ],
   "source": [
    "words_set = set(w2v_model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words_set])\n",
    "                         for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words_set])\n",
    "                         for ls in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc8dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect_avg = []\n",
    "i = 0\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(np.append(v.mean(axis=0),X_train_sentiment[i]))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.append(np.zeros(100, dtype=float),X_train_sentiment[i]))\n",
    "    i=i+1\n",
    "        \n",
    "X_test_vect_avg = []\n",
    "i = 0\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(np.append(v.mean(axis=0),X_test_sentiment[i]))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.append(np.zeros(100, dtype=float),X_test_sentiment[i]))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96ff94e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression f1 score:  0.5321260665157582\n",
      "Logistic Regression accuracy score:  0.5233280113535569\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train_vect_avg)\n",
    "X_test_scale = scaler.fit_transform(X_test_vect_avg)\n",
    "lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_scale)\n",
    "\n",
    "print('Logistic Regression f1 score: ', f1_score(y_test, y_pred, average='binary'))\n",
    "print(\"Logistic Regression accuracy score: \", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "372e4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(lda_model,open('topic_model.sav','wb'))\n",
    "pickle.dump(lr_lda,open('lr_topic_model.sav','wb'))\n",
    "pickle.dump(lr,open('lr.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49c4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
